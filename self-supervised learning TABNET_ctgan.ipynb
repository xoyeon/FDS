{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beaa3c29",
   "metadata": {},
   "source": [
    "- https://medium.com/@vanillaxiangshuyang/self-supervised-learning-on-tabular-data-with-tabnet-544b3ec85cee\n",
    "- https://colab.research.google.com/drive/1P8Obe07DP3VeOld08ThyT1HnChLip_LO#scrollTo=gvy9vUUNOP0W\n",
    "\n",
    "- https://www.kaggle.com/code/sisharaneranjana/semi-supervised-pre-training-with-tabnet#%F0%9F%94%8FDescription-of-the-dataset-\n",
    "- https://dacon.io/en/codeshare/3837"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "133d6436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09afb566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원본 데이터\n",
    "with open(\"./dataset/creditcard.pkl\",\"rb\") as file:\n",
    "    data = pickle.load(file)\n",
    "    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7392ef24",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b17a9bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "\n",
    "# Time 을 일중 시간으로 변환\n",
    "df.loc[:, \"Time\"] = df.loc[:, \"Time\"].apply(lambda x : x / 3600 % 24)\n",
    "\n",
    "# Amount column 은 편차가 크므로 log-scale 로 변환\n",
    "df['Amount'] = np.log(df.pop('Amount') + 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ced8e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>5.008105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>0.989913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000278</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>5.936641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000278</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>4.816249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000556</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>4.248367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0  0.000000 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1  0.000000  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2  0.000278 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3  0.000278 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4  0.000556 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "\n",
       "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
       "0  0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4  0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Class    Amount  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053      0  5.008105  \n",
       "1  0.167170  0.125895 -0.008983  0.014724      0  0.989913  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752      0  5.936641  \n",
       "3  0.647376 -0.221929  0.062723  0.061458      0  4.816249  \n",
       "4 -0.206010  0.502292  0.219422  0.215153      0  4.248367  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaacba4",
   "metadata": {},
   "source": [
    "# train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55434ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f0340ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.values\n",
    "labels = np.array(df.pop('Class'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0af8321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape:  (71201, 31)\n",
      "Y train shape:  (71201,)\n",
      "===============\n",
      "X validation shape:  (71202, 31)\n",
      "y validation shape:  (71202,)\n",
      "===============\n",
      "X test shape:  (142404, 31)\n",
      "Y test shape:  (142404,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.5, random_state=0, stratify=labels)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.5, random_state=0)\n",
    "\n",
    "print(\"X train shape: \", X_train.shape)\n",
    "print(\"Y train shape: \", y_train.shape)\n",
    "print(\"===============\")\n",
    "print(\"X validation shape: \", X_val.shape)\n",
    "print(\"y validation shape: \", y_val.shape)\n",
    "print(\"===============\")\n",
    "print(\"X test shape: \", X_test.shape)\n",
    "print(\"Y test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bac72bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "x_val= sc.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af6520d",
   "metadata": {},
   "source": [
    "# TabNetClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ac5bab",
   "metadata": {},
   "source": [
    "https://github.com/dreamquark-ai/tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35d0835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on the whole dataset with labels\n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "supervised = TabNetClassifier(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    scheduler_params={\"step_size\":10, # how to use learning rate scheduler\n",
    "                      \"gamma\":0.9},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    mask_type='sparsemax' # This will be overwritten if using pretrain model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80dd707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.metrics import Metric\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class F1_Score(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"f1\"\n",
    "        self._maximize = True\n",
    "\n",
    "    def __call__(self, y_true, y_score):\n",
    "        score = f1_score(y_true, (y_score[:, 1]>0.5)*1)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55f92b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.04237 | val_0_logloss: 0.01191 | val_0_f1: 0.03279 | val_1_logloss: 0.01335 | val_1_f1: 0.03053 |  0:00:09s\n",
      "epoch 1  | loss: 0.00929 | val_0_logloss: 0.00751 | val_0_f1: 0.53801 | val_1_logloss: 0.00917 | val_1_f1: 0.39053 |  0:00:17s\n",
      "epoch 2  | loss: 0.00557 | val_0_logloss: 0.00422 | val_0_f1: 0.76415 | val_1_logloss: 0.00597 | val_1_f1: 0.72146 |  0:00:25s\n",
      "epoch 3  | loss: 0.00502 | val_0_logloss: 0.00488 | val_0_f1: 0.63212 | val_1_logloss: 0.00653 | val_1_f1: 0.58883 |  0:00:32s\n",
      "epoch 4  | loss: 0.00531 | val_0_logloss: 0.0044  | val_0_f1: 0.74286 | val_1_logloss: 0.00625 | val_1_f1: 0.65385 |  0:00:40s\n",
      "epoch 5  | loss: 0.00557 | val_0_logloss: 0.00428 | val_0_f1: 0.68783 | val_1_logloss: 0.00591 | val_1_f1: 0.6114  |  0:00:48s\n",
      "epoch 6  | loss: 0.00495 | val_0_logloss: 0.00416 | val_0_f1: 0.79464 | val_1_logloss: 0.00571 | val_1_f1: 0.69828 |  0:00:56s\n",
      "epoch 7  | loss: 0.00437 | val_0_logloss: 0.00299 | val_0_f1: 0.78261 | val_1_logloss: 0.00453 | val_1_f1: 0.73239 |  0:01:03s\n",
      "epoch 8  | loss: 0.00392 | val_0_logloss: 0.00573 | val_0_f1: 0.62827 | val_1_logloss: 0.00872 | val_1_f1: 0.57286 |  0:01:11s\n",
      "epoch 9  | loss: 0.00623 | val_0_logloss: 0.00647 | val_0_f1: 0.49102 | val_1_logloss: 0.00822 | val_1_f1: 0.46927 |  0:01:19s\n",
      "epoch 10 | loss: 0.00588 | val_0_logloss: 0.00476 | val_0_f1: 0.49412 | val_1_logloss: 0.00728 | val_1_f1: 0.2994  |  0:01:26s\n",
      "epoch 11 | loss: 0.00441 | val_0_logloss: 0.00454 | val_0_f1: 0.79464 | val_1_logloss: 0.00655 | val_1_f1: 0.68224 |  0:01:34s\n",
      "epoch 12 | loss: 0.00407 | val_0_logloss: 0.00336 | val_0_f1: 0.82819 | val_1_logloss: 0.00521 | val_1_f1: 0.74312 |  0:01:42s\n",
      "epoch 13 | loss: 0.00362 | val_0_logloss: 0.00227 | val_0_f1: 0.86538 | val_1_logloss: 0.00439 | val_1_f1: 0.75362 |  0:01:50s\n",
      "epoch 14 | loss: 0.00324 | val_0_logloss: 0.00214 | val_0_f1: 0.8599  | val_1_logloss: 0.00418 | val_1_f1: 0.77512 |  0:01:57s\n",
      "epoch 15 | loss: 0.00322 | val_0_logloss: 0.00272 | val_0_f1: 0.76498 | val_1_logloss: 0.00509 | val_1_f1: 0.63462 |  0:02:05s\n",
      "epoch 16 | loss: 0.00333 | val_0_logloss: 0.0026  | val_0_f1: 0.76699 | val_1_logloss: 0.00498 | val_1_f1: 0.63366 |  0:02:13s\n",
      "epoch 17 | loss: 0.00268 | val_0_logloss: 0.00226 | val_0_f1: 0.85345 | val_1_logloss: 0.00432 | val_1_f1: 0.74667 |  0:02:20s\n",
      "epoch 18 | loss: 0.00248 | val_0_logloss: 0.00214 | val_0_f1: 0.83556 | val_1_logloss: 0.00436 | val_1_f1: 0.71889 |  0:02:28s\n",
      "epoch 19 | loss: 0.00264 | val_0_logloss: 0.0022  | val_0_f1: 0.8018  | val_1_logloss: 0.00433 | val_1_f1: 0.71296 |  0:02:36s\n",
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 14 and best_val_1_f1 = 0.77512\n"
     ]
    }
   ],
   "source": [
    "supervised.fit(X_train, y_train,\n",
    "               patience=5,\n",
    "               eval_set=[(X_train, y_train), (x_val,y_val)],\n",
    "               eval_metric=['logloss','f1']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58330feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7707317073170733\n"
     ]
    }
   ],
   "source": [
    "predicted_test = supervised.predict(X_test)\n",
    "score = f1_score(y_test,predicted_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da3e71f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "\n",
    "# TabNetPretrainer\n",
    "unsupervised = TabNetPretrainer(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    mask_type='entmax' # \"sparsemax\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19d5344e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.98345 | val_0_unsup_loss_numpy: 217.4924774169922|  0:00:07s\n",
      "epoch 1  | loss: 0.34711 | val_0_unsup_loss_numpy: 266.1296691894531|  0:00:13s\n",
      "epoch 2  | loss: 0.63993 | val_0_unsup_loss_numpy: 40.44477844238281|  0:00:19s\n",
      "epoch 3  | loss: 0.27321 | val_0_unsup_loss_numpy: 289.6617431640625|  0:00:26s\n",
      "epoch 4  | loss: 0.70554 | val_0_unsup_loss_numpy: 242.64297485351562|  0:00:34s\n",
      "epoch 5  | loss: 0.75601 | val_0_unsup_loss_numpy: 222.50965881347656|  0:00:40s\n",
      "epoch 6  | loss: -0.00715| val_0_unsup_loss_numpy: 589.055908203125|  0:00:47s\n",
      "epoch 7  | loss: 0.48132 | val_0_unsup_loss_numpy: 167.38934326171875|  0:00:53s\n",
      "epoch 8  | loss: 0.63309 | val_0_unsup_loss_numpy: 450.40167236328125|  0:01:00s\n",
      "epoch 9  | loss: 0.79176 | val_0_unsup_loss_numpy: 107.77104949951172|  0:01:07s\n",
      "epoch 10 | loss: 0.78177 | val_0_unsup_loss_numpy: 46.169281005859375|  0:01:13s\n",
      "epoch 11 | loss: 0.05704 | val_0_unsup_loss_numpy: 731.3218383789062|  0:01:19s\n",
      "epoch 12 | loss: 0.69741 | val_0_unsup_loss_numpy: 74.9235610961914|  0:01:26s\n",
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_unsup_loss_numpy = 40.44477844238281\n"
     ]
    }
   ],
   "source": [
    "unsupervised.fit(X_train,\n",
    "                 eval_set=[X_val],\n",
    "                 pretraining_ratio=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96de21b",
   "metadata": {},
   "source": [
    "# Pre-trained 된 모델로 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90b0bf74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>472</td>\n",
       "      <td>1.989026</td>\n",
       "      <td>6.759762</td>\n",
       "      <td>-3.436226</td>\n",
       "      <td>7.508126</td>\n",
       "      <td>-2.003154</td>\n",
       "      <td>-1.453226</td>\n",
       "      <td>4.816805</td>\n",
       "      <td>-9.721434</td>\n",
       "      <td>-6.471587</td>\n",
       "      <td>...</td>\n",
       "      <td>13.760328</td>\n",
       "      <td>0.463365</td>\n",
       "      <td>-2.383923</td>\n",
       "      <td>-0.485486</td>\n",
       "      <td>-1.485571</td>\n",
       "      <td>1.296262</td>\n",
       "      <td>0.110573</td>\n",
       "      <td>0.440638</td>\n",
       "      <td>219.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6986</td>\n",
       "      <td>-2.064557</td>\n",
       "      <td>0.925835</td>\n",
       "      <td>-9.001415</td>\n",
       "      <td>2.821149</td>\n",
       "      <td>2.934994</td>\n",
       "      <td>0.809051</td>\n",
       "      <td>-2.381658</td>\n",
       "      <td>-0.717233</td>\n",
       "      <td>-1.331499</td>\n",
       "      <td>...</td>\n",
       "      <td>1.226586</td>\n",
       "      <td>1.401159</td>\n",
       "      <td>-0.804631</td>\n",
       "      <td>-0.842344</td>\n",
       "      <td>-0.119244</td>\n",
       "      <td>0.886038</td>\n",
       "      <td>0.461688</td>\n",
       "      <td>0.224494</td>\n",
       "      <td>357.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6986</td>\n",
       "      <td>-0.695426</td>\n",
       "      <td>0.619314</td>\n",
       "      <td>-30.991254</td>\n",
       "      <td>2.067791</td>\n",
       "      <td>-5.309895</td>\n",
       "      <td>1.159233</td>\n",
       "      <td>-2.481335</td>\n",
       "      <td>-0.407266</td>\n",
       "      <td>-7.066150</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.563537</td>\n",
       "      <td>0.418333</td>\n",
       "      <td>-0.282519</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>-1.493152</td>\n",
       "      <td>-0.326489</td>\n",
       "      <td>0.438027</td>\n",
       "      <td>-1.155780</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7535</td>\n",
       "      <td>1.904601</td>\n",
       "      <td>4.020354</td>\n",
       "      <td>-9.863136</td>\n",
       "      <td>4.722613</td>\n",
       "      <td>-3.603447</td>\n",
       "      <td>-3.186403</td>\n",
       "      <td>0.689895</td>\n",
       "      <td>-10.156282</td>\n",
       "      <td>0.433262</td>\n",
       "      <td>...</td>\n",
       "      <td>2.174024</td>\n",
       "      <td>0.633162</td>\n",
       "      <td>-1.026630</td>\n",
       "      <td>0.347991</td>\n",
       "      <td>-0.447925</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>-2.555247</td>\n",
       "      <td>-1.000923</td>\n",
       "      <td>45.49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7543</td>\n",
       "      <td>-11.704200</td>\n",
       "      <td>6.025343</td>\n",
       "      <td>-5.197522</td>\n",
       "      <td>1.851403</td>\n",
       "      <td>4.832916</td>\n",
       "      <td>-0.518359</td>\n",
       "      <td>0.454355</td>\n",
       "      <td>-5.387303</td>\n",
       "      <td>-4.300301</td>\n",
       "      <td>...</td>\n",
       "      <td>1.353062</td>\n",
       "      <td>1.197828</td>\n",
       "      <td>-4.923546</td>\n",
       "      <td>0.573469</td>\n",
       "      <td>-0.704693</td>\n",
       "      <td>0.569465</td>\n",
       "      <td>-0.046174</td>\n",
       "      <td>-0.136388</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time         V1        V2         V3        V4        V5        V6  \\\n",
       "0   472   1.989026  6.759762  -3.436226  7.508126 -2.003154 -1.453226   \n",
       "1  6986  -2.064557  0.925835  -9.001415  2.821149  2.934994  0.809051   \n",
       "2  6986  -0.695426  0.619314 -30.991254  2.067791 -5.309895  1.159233   \n",
       "3  7535   1.904601  4.020354  -9.863136  4.722613 -3.603447 -3.186403   \n",
       "4  7543 -11.704200  6.025343  -5.197522  1.851403  4.832916 -0.518359   \n",
       "\n",
       "         V7         V8        V9  ...        V21       V22       V23  \\\n",
       "0  4.816805  -9.721434 -6.471587  ...  13.760328  0.463365 -2.383923   \n",
       "1 -2.381658  -0.717233 -1.331499  ...   1.226586  1.401159 -0.804631   \n",
       "2 -2.481335  -0.407266 -7.066150  ...  -3.563537  0.418333 -0.282519   \n",
       "3  0.689895 -10.156282  0.433262  ...   2.174024  0.633162 -1.026630   \n",
       "4  0.454355  -5.387303 -4.300301  ...   1.353062  1.197828 -4.923546   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Amount  Class  \n",
       "0 -0.485486 -1.485571  1.296262  0.110573  0.440638  219.80      1  \n",
       "1 -0.842344 -0.119244  0.886038  0.461688  0.224494  357.95      1  \n",
       "2  0.912088 -1.493152 -0.326489  0.438027 -1.155780    3.22      1  \n",
       "3  0.347991 -0.447925  0.185000 -2.555247 -1.000923   45.49      1  \n",
       "4  0.573469 -0.704693  0.569465 -0.046174 -0.136388    1.00      1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated = pd.read_csv('./dataset/ctgan_generated_0320.csv')\n",
    "generated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74e69ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.131111</td>\n",
       "      <td>1.989026</td>\n",
       "      <td>6.759762</td>\n",
       "      <td>-3.436226</td>\n",
       "      <td>7.508126</td>\n",
       "      <td>-2.003154</td>\n",
       "      <td>-1.453226</td>\n",
       "      <td>4.816805</td>\n",
       "      <td>-9.721434</td>\n",
       "      <td>-6.471587</td>\n",
       "      <td>...</td>\n",
       "      <td>13.760328</td>\n",
       "      <td>0.463365</td>\n",
       "      <td>-2.383923</td>\n",
       "      <td>-0.485486</td>\n",
       "      <td>-1.485571</td>\n",
       "      <td>1.296262</td>\n",
       "      <td>0.110573</td>\n",
       "      <td>0.440638</td>\n",
       "      <td>1</td>\n",
       "      <td>5.392723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.940556</td>\n",
       "      <td>-2.064557</td>\n",
       "      <td>0.925835</td>\n",
       "      <td>-9.001415</td>\n",
       "      <td>2.821149</td>\n",
       "      <td>2.934994</td>\n",
       "      <td>0.809051</td>\n",
       "      <td>-2.381658</td>\n",
       "      <td>-0.717233</td>\n",
       "      <td>-1.331499</td>\n",
       "      <td>...</td>\n",
       "      <td>1.226586</td>\n",
       "      <td>1.401159</td>\n",
       "      <td>-0.804631</td>\n",
       "      <td>-0.842344</td>\n",
       "      <td>-0.119244</td>\n",
       "      <td>0.886038</td>\n",
       "      <td>0.461688</td>\n",
       "      <td>0.224494</td>\n",
       "      <td>1</td>\n",
       "      <td>5.880396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.940556</td>\n",
       "      <td>-0.695426</td>\n",
       "      <td>0.619314</td>\n",
       "      <td>-30.991254</td>\n",
       "      <td>2.067791</td>\n",
       "      <td>-5.309895</td>\n",
       "      <td>1.159233</td>\n",
       "      <td>-2.481335</td>\n",
       "      <td>-0.407266</td>\n",
       "      <td>-7.066150</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.563537</td>\n",
       "      <td>0.418333</td>\n",
       "      <td>-0.282519</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>-1.493152</td>\n",
       "      <td>-0.326489</td>\n",
       "      <td>0.438027</td>\n",
       "      <td>-1.155780</td>\n",
       "      <td>1</td>\n",
       "      <td>1.169692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.093056</td>\n",
       "      <td>1.904601</td>\n",
       "      <td>4.020354</td>\n",
       "      <td>-9.863136</td>\n",
       "      <td>4.722613</td>\n",
       "      <td>-3.603447</td>\n",
       "      <td>-3.186403</td>\n",
       "      <td>0.689895</td>\n",
       "      <td>-10.156282</td>\n",
       "      <td>0.433262</td>\n",
       "      <td>...</td>\n",
       "      <td>2.174024</td>\n",
       "      <td>0.633162</td>\n",
       "      <td>-1.026630</td>\n",
       "      <td>0.347991</td>\n",
       "      <td>-0.447925</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>-2.555247</td>\n",
       "      <td>-1.000923</td>\n",
       "      <td>1</td>\n",
       "      <td>3.817515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.095278</td>\n",
       "      <td>-11.704200</td>\n",
       "      <td>6.025343</td>\n",
       "      <td>-5.197522</td>\n",
       "      <td>1.851403</td>\n",
       "      <td>4.832916</td>\n",
       "      <td>-0.518359</td>\n",
       "      <td>0.454355</td>\n",
       "      <td>-5.387303</td>\n",
       "      <td>-4.300301</td>\n",
       "      <td>...</td>\n",
       "      <td>1.353062</td>\n",
       "      <td>1.197828</td>\n",
       "      <td>-4.923546</td>\n",
       "      <td>0.573469</td>\n",
       "      <td>-0.704693</td>\n",
       "      <td>0.569465</td>\n",
       "      <td>-0.046174</td>\n",
       "      <td>-0.136388</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time         V1        V2         V3        V4        V5        V6  \\\n",
       "0  0.131111   1.989026  6.759762  -3.436226  7.508126 -2.003154 -1.453226   \n",
       "1  1.940556  -2.064557  0.925835  -9.001415  2.821149  2.934994  0.809051   \n",
       "2  1.940556  -0.695426  0.619314 -30.991254  2.067791 -5.309895  1.159233   \n",
       "3  2.093056   1.904601  4.020354  -9.863136  4.722613 -3.603447 -3.186403   \n",
       "4  2.095278 -11.704200  6.025343  -5.197522  1.851403  4.832916 -0.518359   \n",
       "\n",
       "         V7         V8        V9  ...        V21       V22       V23  \\\n",
       "0  4.816805  -9.721434 -6.471587  ...  13.760328  0.463365 -2.383923   \n",
       "1 -2.381658  -0.717233 -1.331499  ...   1.226586  1.401159 -0.804631   \n",
       "2 -2.481335  -0.407266 -7.066150  ...  -3.563537  0.418333 -0.282519   \n",
       "3  0.689895 -10.156282  0.433262  ...   2.174024  0.633162 -1.026630   \n",
       "4  0.454355  -5.387303 -4.300301  ...   1.353062  1.197828 -4.923546   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class    Amount  \n",
       "0 -0.485486 -1.485571  1.296262  0.110573  0.440638      1  5.392723  \n",
       "1 -0.842344 -0.119244  0.886038  0.461688  0.224494      1  5.880396  \n",
       "2  0.912088 -1.493152 -0.326489  0.438027 -1.155780      1  1.169692  \n",
       "3  0.347991 -0.447925  0.185000 -2.555247 -1.000923      1  3.817515  \n",
       "4  0.573469 -0.704693  0.569465 -0.046174 -0.136388      1  0.001000  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 전처리\n",
    "ctgan = generated.copy()\n",
    "\n",
    "# Time 을 일중 시간으로 변환\n",
    "ctgan.loc[:, \"Time\"] = ctgan.loc[:, \"Time\"].apply(lambda x : x / 3600 % 24)\n",
    "\n",
    "# Amount column 은 편차가 크므로 log-scale 로 변환\n",
    "eps=0.001\n",
    "ctgan['Amount'] = np.log(ctgan.pop('Amount') + eps)\n",
    "\n",
    "ctgan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9baa4e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctgan_features = ctgan.values\n",
    "ctgan_labels = np.array(ctgan.pop('Class'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98d759f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(ctgan_features, ctgan_labels, test_size=0.5, random_state=0, stratify=ctgan_labels)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1d15267",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = TabNetClassifier(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    scheduler_params={\"step_size\":10, # how to use learning rate scheduler\n",
    "                      \"gamma\":0.9},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    mask_type='sparsemax' # This will be overwritten if using pretrain model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb997d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.0     | train_logloss: 0.59294 | train_f1: 0.31884 | valid_logloss: 0.44945 | valid_f1: 0.38596 |  0:00:00s\n",
      "epoch 1  | loss: 0.0     | train_logloss: 0.59294 | train_f1: 0.31884 | valid_logloss: 0.44945 | valid_f1: 0.38596 |  0:00:00s\n",
      "epoch 2  | loss: 0.0     | train_logloss: 0.59294 | train_f1: 0.31884 | valid_logloss: 0.44945 | valid_f1: 0.38596 |  0:00:00s\n",
      "epoch 3  | loss: 0.0     | train_logloss: 0.59294 | train_f1: 0.31884 | valid_logloss: 0.44945 | valid_f1: 0.38596 |  0:00:00s\n",
      "epoch 4  | loss: 0.0     | train_logloss: 0.59294 | train_f1: 0.31884 | valid_logloss: 0.44945 | valid_f1: 0.38596 |  0:00:00s\n",
      "epoch 5  | loss: 0.0     | train_logloss: 0.59294 | train_f1: 0.31884 | valid_logloss: 0.44945 | valid_f1: 0.38596 |  0:00:00s\n",
      "epoch 6  | loss: 0.0     | train_logloss: 0.59294 | train_f1: 0.31884 | valid_logloss: 0.44945 | valid_f1: 0.38596 |  0:00:00s\n",
      "epoch 7  | loss: 0.0     | train_logloss: 0.59294 | train_f1: 0.31884 | valid_logloss: 0.44945 | valid_f1: 0.38596 |  0:00:00s\n",
      "epoch 8  | loss: 0.0     | train_logloss: 0.59294 | train_f1: 0.31884 | valid_logloss: 0.44945 | valid_f1: 0.38596 |  0:00:00s\n",
      "epoch 9  | loss: 0.0     | train_logloss: 0.59294 | train_f1: 0.31884 | valid_logloss: 0.44945 | valid_f1: 0.38596 |  0:00:00s\n",
      "epoch 10 | loss: 0.0     | train_logloss: 0.59294 | train_f1: 0.31884 | valid_logloss: 0.44945 | valid_f1: 0.38596 |  0:00:00s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_valid_f1 = 0.38596\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train,y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['logloss','f1'],\n",
    "    from_unsupervised=unsupervised\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "398e9c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36065573770491804\n"
     ]
    }
   ],
   "source": [
    "predicted_test=clf.predict(X_test)\n",
    "score=f1_score(y_test,predicted_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fa49bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soyeon",
   "language": "python",
   "name": "soyeon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

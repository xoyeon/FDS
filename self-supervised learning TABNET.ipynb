{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beaa3c29",
   "metadata": {},
   "source": [
    "- https://medium.com/@vanillaxiangshuyang/self-supervised-learning-on-tabular-data-with-tabnet-544b3ec85cee\n",
    "- https://colab.research.google.com/drive/1P8Obe07DP3VeOld08ThyT1HnChLip_LO#scrollTo=gvy9vUUNOP0W\n",
    "\n",
    "- https://www.kaggle.com/code/sisharaneranjana/semi-supervised-pre-training-with-tabnet#%F0%9F%94%8FDescription-of-the-dataset-\n",
    "- https://dacon.io/en/codeshare/3837"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "133d6436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09afb566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원본 데이터\n",
    "with open(\"./dataset/creditcard.pkl\",\"rb\") as file:\n",
    "    data = pickle.load(file)\n",
    "    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7392ef24",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b17a9bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "\n",
    "# Time 을 일중 시간으로 변환\n",
    "df.loc[:, \"Time\"] = df.loc[:, \"Time\"].apply(lambda x : x / 3600 % 24)\n",
    "\n",
    "# Amount column 은 편차가 크므로 log-scale 로 변환\n",
    "df['Amount'] = np.log(df.pop('Amount') + 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ced8e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>5.008105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>0.989913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000278</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>5.936641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000278</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>4.816249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000556</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>4.248367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0  0.000000 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1  0.000000  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2  0.000278 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3  0.000278 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4  0.000556 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "\n",
       "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
       "0  0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4  0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Class    Amount  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053      0  5.008105  \n",
       "1  0.167170  0.125895 -0.008983  0.014724      0  0.989913  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752      0  5.936641  \n",
       "3  0.647376 -0.221929  0.062723  0.061458      0  4.816249  \n",
       "4 -0.206010  0.502292  0.219422  0.215153      0  4.248367  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaacba4",
   "metadata": {},
   "source": [
    "# train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55434ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f0340ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.values\n",
    "labels = np.array(df.pop('Class'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0af8321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape:  (71201, 31)\n",
      "X validation shape:  (71202, 31)\n",
      "X test shape:  (142404, 31)\n",
      "Y train shape:  (71201,)\n",
      "Y validation shape:  (71202,)\n",
      "Y test shape:  (142404,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.5, random_state=0, stratify=labels)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.5, random_state=0)\n",
    "\n",
    "print(\"X train shape: \", X_train.shape)\n",
    "print(\"X validation shape: \", X_val.shape)\n",
    "print(\"X test shape: \", X_test.shape)\n",
    "print(\"Y train shape: \", y_train.shape)\n",
    "print(\"Y validation shape: \", y_val.shape)\n",
    "print(\"Y test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bac72bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "x_val= sc.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af6520d",
   "metadata": {},
   "source": [
    "# TabNetClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ac5bab",
   "metadata": {},
   "source": [
    "https://github.com/dreamquark-ai/tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35d0835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on the whole dataset with labels\n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "supervised = TabNetClassifier(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    scheduler_params={\"step_size\":10, # how to use learning rate scheduler\n",
    "                      \"gamma\":0.9},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    mask_type='sparsemax' # This will be overwritten if using pretrain model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80dd707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.metrics import Metric\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class F1_Score(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"f1\"\n",
    "        self._maximize = True\n",
    "\n",
    "    def __call__(self, y_true, y_score):\n",
    "        score = f1_score(y_true, (y_score[:, 1]>0.5)*1)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55f92b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.04237 | val_0_logloss: 0.01191 | val_0_f1: 0.03279 | val_1_logloss: 0.02337 | val_1_f1: 0.04286 |  0:00:08s\n",
      "epoch 1  | loss: 0.00929 | val_0_logloss: 0.00751 | val_0_f1: 0.53801 | val_1_logloss: 0.03121 | val_1_f1: 0.27273 |  0:00:16s\n",
      "epoch 2  | loss: 0.00557 | val_0_logloss: 0.00422 | val_0_f1: 0.76415 | val_1_logloss: 0.01935 | val_1_f1: 0.58883 |  0:00:25s\n",
      "epoch 3  | loss: 0.00502 | val_0_logloss: 0.00488 | val_0_f1: 0.63212 | val_1_logloss: 0.02333 | val_1_f1: 0.49724 |  0:00:33s\n",
      "epoch 4  | loss: 0.00531 | val_0_logloss: 0.0044  | val_0_f1: 0.74286 | val_1_logloss: 0.01511 | val_1_f1: 0.59113 |  0:00:41s\n",
      "epoch 5  | loss: 0.00557 | val_0_logloss: 0.00428 | val_0_f1: 0.68783 | val_1_logloss: 0.01156 | val_1_f1: 0.46486 |  0:00:49s\n",
      "epoch 6  | loss: 0.00495 | val_0_logloss: 0.00416 | val_0_f1: 0.79464 | val_1_logloss: 0.01137 | val_1_f1: 0.47887 |  0:00:57s\n",
      "epoch 7  | loss: 0.00437 | val_0_logloss: 0.00299 | val_0_f1: 0.78261 | val_1_logloss: 0.02135 | val_1_f1: 0.18497 |  0:01:05s\n",
      "epoch 8  | loss: 0.00392 | val_0_logloss: 0.00573 | val_0_f1: 0.62827 | val_1_logloss: 0.01327 | val_1_f1: 0.40909 |  0:01:14s\n",
      "epoch 9  | loss: 0.00623 | val_0_logloss: 0.00647 | val_0_f1: 0.49102 | val_1_logloss: 0.01168 | val_1_f1: 0.32402 |  0:01:22s\n",
      "\n",
      "Early stopping occurred at epoch 9 with best_epoch = 4 and best_val_1_f1 = 0.59113\n"
     ]
    }
   ],
   "source": [
    "supervised.fit(X_train, y_train,\n",
    "               patience=5,\n",
    "               eval_set=[(X_train, y_train), (x_val,y_val)],\n",
    "               eval_metric=['logloss','f1']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58330feb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m predicted_test \u001b[38;5;241m=\u001b[39m supervised\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)\n\u001b[1;32m----> 2\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpredicted_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\soyeon\\lib\\site-packages\\sklearn\\utils\\validation.py:72\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m as keyword args. From version 0.25 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassing these as positional arguments will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult in an error\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(args_msg)),\n\u001b[0;32m     70\u001b[0m                   \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m     71\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate({k: arg \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args)})\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\soyeon\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1044\u001b[0m, in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;129m@_deprecate_positional_args\u001b[39m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf1_score\u001b[39m(y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    927\u001b[0m              sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure\u001b[39;00m\n\u001b[0;32m    929\u001b[0m \n\u001b[0;32m    930\u001b[0m \u001b[38;5;124;03m    The F1 score can be interpreted as a weighted average of the precision and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;124;03m    modified with ``zero_division``.\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbeta_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1045\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1046\u001b[0m \u001b[43m                       \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1047\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\soyeon\\lib\\site-packages\\sklearn\\utils\\validation.py:72\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m as keyword args. From version 0.25 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassing these as positional arguments will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult in an error\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(args_msg)),\n\u001b[0;32m     70\u001b[0m                   \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m     71\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate({k: arg \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args)})\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\soyeon\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1168\u001b[0m, in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;129m@_deprecate_positional_args\u001b[39m\n\u001b[0;32m   1051\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfbeta_score\u001b[39m(y_true, y_pred, \u001b[38;5;241m*\u001b[39m, beta, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1052\u001b[0m                 average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the F-beta score\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \n\u001b[0;32m   1055\u001b[0m \u001b[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;124;03m    modified with ``zero_division``.\u001b[39;00m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1168\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1169\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1170\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1171\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1172\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1173\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf-score\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1174\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\soyeon\\lib\\site-packages\\sklearn\\utils\\validation.py:72\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m as keyword args. From version 0.25 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassing these as positional arguments will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult in an error\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(args_msg)),\n\u001b[0;32m     70\u001b[0m                   \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m     71\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate({k: arg \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args)})\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\soyeon\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1433\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1432\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta should be >=0 in the F-beta score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1433\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1434\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1436\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1437\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\soyeon\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1250\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m average_options \u001b[38;5;129;01mand\u001b[39;00m average \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m   1248\u001b[0m                      \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[1;32m-> 1250\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1251\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\soyeon\\lib\\site-packages\\sklearn\\metrics\\_classification.py:90\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     87\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 90\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     91\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(type_true, type_pred))\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m     94\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "predicted_test = supervised.predict_proba(X_test)\n",
    "score = f1_score(y_test,predicted_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da3e71f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "\n",
    "# TabNetPretrainer\n",
    "unsupervised = TabNetPretrainer(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    mask_type='entmax' # \"sparsemax\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19d5344e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.98345 | val_0_unsup_loss_numpy: 217.4924774169922|  0:00:06s\n",
      "epoch 1  | loss: 0.34711 | val_0_unsup_loss_numpy: 266.1296691894531|  0:00:13s\n",
      "epoch 2  | loss: 0.63993 | val_0_unsup_loss_numpy: 40.44477844238281|  0:00:20s\n",
      "epoch 3  | loss: 0.27321 | val_0_unsup_loss_numpy: 289.6617431640625|  0:00:26s\n",
      "epoch 4  | loss: 0.70554 | val_0_unsup_loss_numpy: 242.64297485351562|  0:00:33s\n",
      "epoch 5  | loss: 0.75601 | val_0_unsup_loss_numpy: 222.50965881347656|  0:00:39s\n",
      "epoch 6  | loss: -0.00715| val_0_unsup_loss_numpy: 589.055908203125|  0:00:46s\n",
      "epoch 7  | loss: 0.48132 | val_0_unsup_loss_numpy: 167.38934326171875|  0:00:52s\n",
      "epoch 8  | loss: 0.63309 | val_0_unsup_loss_numpy: 450.40167236328125|  0:00:59s\n",
      "epoch 9  | loss: 0.79176 | val_0_unsup_loss_numpy: 107.77104949951172|  0:01:06s\n",
      "epoch 10 | loss: 0.78177 | val_0_unsup_loss_numpy: 46.169281005859375|  0:01:12s\n",
      "epoch 11 | loss: 0.05704 | val_0_unsup_loss_numpy: 731.3218383789062|  0:01:19s\n",
      "epoch 12 | loss: 0.69741 | val_0_unsup_loss_numpy: 74.9235610961914|  0:01:26s\n",
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_unsup_loss_numpy = 40.44477844238281\n"
     ]
    }
   ],
   "source": [
    "unsupervised.fit(X_train,\n",
    "                 eval_set=[X_val],\n",
    "                 pretraining_ratio=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96de21b",
   "metadata": {},
   "source": [
    "# Pre-trained 된 모델로 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1d15267",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = TabNetClassifier(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    scheduler_params={\"step_size\":10, # how to use learning rate scheduler\n",
    "                      \"gamma\":0.9},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    mask_type='sparsemax' # This will be overwritten if using pretrain model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb997d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.0316  | train_logloss: 0.00926 | train_f1: 0.25676 | valid_logloss: 0.01494 | valid_f1: 0.01493 |  0:00:07s\n",
      "epoch 1  | loss: 0.00853 | train_logloss: 0.00737 | train_f1: 0.50538 | valid_logloss: 0.01078 | valid_f1: 0.27381 |  0:00:16s\n",
      "epoch 2  | loss: 0.00638 | train_logloss: 0.0048  | train_f1: 0.65766 | valid_logloss: 0.00938 | valid_f1: 0.62264 |  0:00:24s\n",
      "epoch 3  | loss: 0.00485 | train_logloss: 0.00377 | train_f1: 0.76667 | valid_logloss: 0.00722 | valid_f1: 0.69565 |  0:00:31s\n",
      "epoch 4  | loss: 0.00409 | train_logloss: 0.00303 | train_f1: 0.8087  | valid_logloss: 0.00764 | valid_f1: 0.6749  |  0:00:38s\n",
      "epoch 5  | loss: 0.00381 | train_logloss: 0.00328 | train_f1: 0.82819 | valid_logloss: 0.00808 | valid_f1: 0.69492 |  0:00:46s\n",
      "epoch 6  | loss: 0.00293 | train_logloss: 0.00378 | train_f1: 0.8658  | valid_logloss: 0.00755 | valid_f1: 0.66667 |  0:00:53s\n",
      "epoch 7  | loss: 0.00248 | train_logloss: 0.00204 | train_f1: 0.89831 | valid_logloss: 0.00671 | valid_f1: 0.68868 |  0:01:00s\n",
      "epoch 8  | loss: 0.00173 | train_logloss: 0.00079 | train_f1: 0.93333 | valid_logloss: 0.00678 | valid_f1: 0.61    |  0:01:07s\n",
      "epoch 9  | loss: 0.00133 | train_logloss: 0.00028 | train_f1: 0.98276 | valid_logloss: 0.008   | valid_f1: 0.2069  |  0:01:15s\n",
      "epoch 10 | loss: 0.00068 | train_logloss: 0.00023 | train_f1: 0.99145 | valid_logloss: 0.00933 | valid_f1: 0.0     |  0:01:22s\n",
      "epoch 11 | loss: 0.00052 | train_logloss: 0.00018 | train_f1: 0.99145 | valid_logloss: 0.01058 | valid_f1: 0.0     |  0:01:29s\n",
      "epoch 12 | loss: 0.00044 | train_logloss: 0.00017 | train_f1: 0.99153 | valid_logloss: 0.01181 | valid_f1: 0.0     |  0:01:36s\n",
      "epoch 13 | loss: 0.00041 | train_logloss: 0.00013 | train_f1: 0.99574 | valid_logloss: 0.0116  | valid_f1: 0.0     |  0:01:44s\n",
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_valid_f1 = 0.69565\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train,y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['logloss','f1'],\n",
    "    from_unsupervised=unsupervised\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "398e9c33",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf_partial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predicted_test\u001b[38;5;241m=\u001b[39m\u001b[43mclf_partial\u001b[49m\u001b[38;5;241m.\u001b[39mpredict_proba(x_test)[:,\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      2\u001b[0m score\u001b[38;5;241m=\u001b[39mroc_auc_score(y_test,predicted_test)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(score)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf_partial' is not defined"
     ]
    }
   ],
   "source": [
    "predicted_test=clf_partial.predict_proba(x_test)[:,1]\n",
    "score=roc_auc_score(y_test,predicted_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fa49bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soyeon",
   "language": "python",
   "name": "soyeon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

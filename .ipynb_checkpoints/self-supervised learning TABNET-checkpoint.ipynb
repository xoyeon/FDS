{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beaa3c29",
   "metadata": {},
   "source": [
    "- https://medium.com/@vanillaxiangshuyang/self-supervised-learning-on-tabular-data-with-tabnet-544b3ec85cee\n",
    "- https://colab.research.google.com/drive/1P8Obe07DP3VeOld08ThyT1HnChLip_LO#scrollTo=gvy9vUUNOP0W\n",
    "\n",
    "- https://www.kaggle.com/code/sisharaneranjana/semi-supervised-pre-training-with-tabnet#%F0%9F%94%8FDescription-of-the-dataset-\n",
    "- https://dacon.io/en/codeshare/3837"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "133d6436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09afb566",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './dataset/creditcard.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 원본 데이터\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./dataset/creditcard.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      3\u001b[0m     data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m      5\u001b[0m data\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './dataset/creditcard.pkl'"
     ]
    }
   ],
   "source": [
    "# 원본 데이터\n",
    "with open(\"./dataset/creditcard.pkl\",\"rb\") as file:\n",
    "    data = pickle.load(file)\n",
    "    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7392ef24",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17a9bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "\n",
    "# Time 을 일중 시간으로 변환\n",
    "df.loc[:, \"Time\"] = df.loc[:, \"Time\"].apply(lambda x : x / 3600 % 24)\n",
    "\n",
    "# Amount column 은 편차가 크므로 log-scale 로 변환\n",
    "df['Amount'] = np.log(df.pop('Amount') + 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ced8e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaacba4",
   "metadata": {},
   "source": [
    "# train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55434ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0340ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.values\n",
    "labels = np.array(df.pop('Class'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0af8321",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.5, random_state=0, stratify=labels)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.5, random_state=0)\n",
    "\n",
    "print(\"X train shape: \", X_train.shape)\n",
    "print(\"X validation shape: \", X_val.shape)\n",
    "print(\"X test shape: \", X_test.shape)\n",
    "print(\"Y train shape: \", y_train.shape)\n",
    "print(\"Y validation shape: \", y_val.shape)\n",
    "print(\"Y test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac72bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "x_val= sc.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af6520d",
   "metadata": {},
   "source": [
    "# TabNetClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ac5bab",
   "metadata": {},
   "source": [
    "https://github.com/dreamquark-ai/tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d0835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on the whole dataset with labels\n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "supervised = TabNetClassifier(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    scheduler_params={\"step_size\":10, # how to use learning rate scheduler\n",
    "                      \"gamma\":0.9},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    mask_type='sparsemax' # This will be overwritten if using pretrain model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dd707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.metrics import Metric\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class F1_Score(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"f1\"\n",
    "        self._maximize = True\n",
    "\n",
    "    def __call__(self, y_true, y_score):\n",
    "        score = f1_score(y_true, (y_score[:, 1]>0.5)*1)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f92b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised.fit(X_train, y_train,\n",
    "               patience=5,\n",
    "               eval_set=[(X_train, y_train), (x_val,y_val)],\n",
    "               eval_metric=['logloss','f1']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58330feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test = supervised.predict_proba(X_test)\n",
    "score = f1_score(y_test,predicted_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e71f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "\n",
    "# TabNetPretrainer\n",
    "unsupervised = TabNetPretrainer(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    mask_type='entmax' # \"sparsemax\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d5344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised.fit(X_train,\n",
    "                 eval_set=[X_val],\n",
    "                 pretraining_ratio=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96de21b",
   "metadata": {},
   "source": [
    "# Pre-trained 된 모델로 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d15267",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = TabNetClassifier(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    scheduler_params={\"step_size\":10, # how to use learning rate scheduler\n",
    "                      \"gamma\":0.9},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    mask_type='sparsemax' # This will be overwritten if using pretrain model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb997d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['logloss','f1'],\n",
    "    from_unsupervised=unsupervised\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398e9c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test=clf.predict_proba(x_test)[:,1]\n",
    "score=roc_auc_score(y_test,predicted_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fa49bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soyeon",
   "language": "python",
   "name": "soyeon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
